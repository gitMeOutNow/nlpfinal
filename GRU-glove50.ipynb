{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRU-glove50.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOA/YWf2orHqVw+Wl/+jCFN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RtcAZw7N0_K","executionInfo":{"status":"ok","timestamp":1650937627069,"user_tz":300,"elapsed":21120,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"f4a0af98-aa18-4241-d681-8a1074552ccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# mounting drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch import optim\n","import random\n","from copy import deepcopy\n","import time\n","import pprint"],"metadata":{"id":"_YRfHVb4OTes","executionInfo":{"status":"ok","timestamp":1650937629956,"user_tz":300,"elapsed":2891,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxFqC_DE7vEn","executionInfo":{"status":"ok","timestamp":1650937629956,"user_tz":300,"elapsed":9,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"00513156-e4ce-43c8-9b1d-b0a0da504149"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["# read in classification dataset and store in dataframe\n","df = pd.read_csv('/content/gdrive/MyDrive/data/classification_data/classification_train.tsv', sep=' ', index_col=0)"],"metadata":{"id":"-2dLSrv0OT_F","executionInfo":{"status":"ok","timestamp":1650937634509,"user_tz":300,"elapsed":4556,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.head(n=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"ryAPtH2KOfOH","executionInfo":{"status":"ok","timestamp":1650937634510,"user_tz":300,"elapsed":5,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"97247584-f6fb-46df-adf6-5788d3a66671"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       class                                           sentence\n","0  chemistry  the approximate analysis of nonlinear behavior...\n","1  chemistry  flow of particles through slits in the bottom ...\n","2  chemistry  scanning probe memories technology and applica...\n","3  chemistry  influence of disodium hydrogen phosphate dodec...\n","4  chemistry  highly luminescent lead bromide perovskite nan...\n","5  chemistry  condensation of propiolic esters with olefins ...\n","6  chemistry  anisotropy of paramagnetic susceptibility of c...\n","7  chemistry  the use of copper standards with copper fluori...\n","8  chemistry  nucleation of silicalite precursors during syn...\n","9  chemistry  analytical procedure for the determination of ..."],"text/html":["\n","  <div id=\"df-d6c52584-139e-42cb-8a4f-f166e97eedfd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>chemistry</td>\n","      <td>the approximate analysis of nonlinear behavior...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>chemistry</td>\n","      <td>flow of particles through slits in the bottom ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>chemistry</td>\n","      <td>scanning probe memories technology and applica...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>chemistry</td>\n","      <td>influence of disodium hydrogen phosphate dodec...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>chemistry</td>\n","      <td>highly luminescent lead bromide perovskite nan...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>chemistry</td>\n","      <td>condensation of propiolic esters with olefins ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>chemistry</td>\n","      <td>anisotropy of paramagnetic susceptibility of c...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>chemistry</td>\n","      <td>the use of copper standards with copper fluori...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>chemistry</td>\n","      <td>nucleation of silicalite precursors during syn...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>chemistry</td>\n","      <td>analytical procedure for the determination of ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6c52584-139e-42cb-8a4f-f166e97eedfd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d6c52584-139e-42cb-8a4f-f166e97eedfd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6c52584-139e-42cb-8a4f-f166e97eedfd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_percent = 0.2\n","validation_percent = 0.05\n","test_percent = 0.05\n","\n","df = df.sample(frac=1)\n","a = int(len(df)*train_percent)\n","b = int(a + len(df)*validation_percent)\n","c = int(b + len(df)*test_percent)\n","\n","train_data = df[0:a]\n","validation_data = df[a:b]\n","test_data = df[b:c]\n","\n","print(train_data.head())\n","print(validation_data.head())\n","print(test_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDKMmp8mOfI9","executionInfo":{"status":"ok","timestamp":1650937634878,"user_tz":300,"elapsed":372,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"2152d244-ceb7-4d1b-814f-6f5cf1b77e42"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["              class                                           sentence\n","1322593   sociology  toward traditional or atypical parenting media...\n","1147574  psychology  research in the classroom thinking about resea...\n","130959    chemistry  additions and corrections absorption spectra o...\n","860850      polisci  philanthropy heirs values how successful famil...\n","1004911  psychology  p310 baep and sep as electrophysiological stud...\n","             class                                           sentence\n","357531   economics  private sector participation in water supply a...\n","782738     polisci                       women against the good war\\n\n","1266888  sociology  straddling the boundary messianic judaism and ...\n","106411   chemistry           polarographic determination of nitrate\\n\n","406799   economics  economic geography and endogenous determinatio...\n","              class                                           sentence\n","371166    economics  modern portfolio theory s third rail achieving...\n","1299101   sociology  getting off on the wrong foot restoring trust ...\n","1004975  psychology  sex role identity academic stress and wellbein...\n","834614      polisci  the democratic party and the negro northern an...\n","589276    economics        the oxford handbook of credit derivatives\\n\n"]}]},{"cell_type":"code","source":["train_data['class'].hist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"eI4uRDUDOooT","executionInfo":{"status":"ok","timestamp":1650937635166,"user_tz":300,"elapsed":292,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"fcc4b494-094f-444a-8878-a4eb4c3f54d2"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fc0511d4910>"]},"metadata":{},"execution_count":7},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["class SentenceExample:\n","    \"\"\"\n","    Data wrapper for a single example for sentiment analysis.\n","\n","    Attributes:\n","        words (List[string]): list of words\n","        label (int): 0 or 1 (0 = negative, 1 = positive)\n","    \"\"\"\n","\n","    def __init__(self, words, label):\n","        self.words = words\n","        self.label = label\n","\n","    def __repr__(self):\n","        return repr(self.words) + \"; label=\" + repr(self.label)\n","\n","    def __str__(self):\n","        return self.__repr__()"],"metadata":{"id":"uzpkMHNgOteE","executionInfo":{"status":"ok","timestamp":1650937635166,"user_tz":300,"elapsed":6,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["CLASS_LABELS = {\n","    'chemistry': 0,\n","    'economics': 1,\n","    'polisci' : 2,\n","    'psychology' : 3,\n","    'sociology' : 4\n","}"],"metadata":{"id":"fNdN1792Owfi","executionInfo":{"status":"ok","timestamp":1650937635290,"user_tz":300,"elapsed":129,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_exs = []\n","for i, row in train_data.iterrows():\n","  sentence = row['sentence'].split(' ')\n","  sentence[-1] = sentence[-1].strip()\n","  train_exs.append(SentenceExample(sentence, CLASS_LABELS[row['class']]))"],"metadata":{"id":"0KpxxnLMOyia","executionInfo":{"status":"ok","timestamp":1650937650623,"user_tz":300,"elapsed":15335,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["validation_exs = []\n","for i, row in validation_data.iterrows():\n","  sentence = row['sentence'].split(' ')\n","  sentence[-1] = sentence[-1].strip()\n","  validation_exs.append(SentenceExample(sentence, CLASS_LABELS[row['class']]))"],"metadata":{"id":"LmGtBe5XOzF4","executionInfo":{"status":"ok","timestamp":1650937654569,"user_tz":300,"elapsed":3949,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test_exs = []\n","for i, row in test_data.iterrows():\n","  sentence = row['sentence'].split(' ')\n","  sentence[-1] = sentence[-1].strip()\n","  test_exs.append(SentenceExample(sentence, CLASS_LABELS[row['class']]))"],"metadata":{"id":"GRD0RcCnO0yI","executionInfo":{"status":"ok","timestamp":1650937658627,"user_tz":300,"elapsed":4061,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XxgpuRqvO0s1","executionInfo":{"status":"ok","timestamp":1650937658627,"user_tz":300,"elapsed":9,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class Indexer(object):\n","    \"\"\"\n","    Bijection between objects and integers starting at 0. Useful for mapping\n","    labels, features, etc. into coordinates of a vector space.\n","\n","    Attributes:\n","        objs_to_ints\n","        ints_to_objs\n","    \"\"\"\n","    def __init__(self):\n","        self.objs_to_ints = {}\n","        self.ints_to_objs = {}\n","\n","    def __repr__(self):\n","        return str([str(self.get_object(i)) for i in range(0, len(self))])\n","\n","    def __str__(self):\n","        return self.__repr__()\n","\n","    def __len__(self):\n","        return len(self.objs_to_ints)\n","\n","    def get_object(self, index):\n","        \"\"\"\n","        :param index: integer index to look up\n","        :return: Returns the object corresponding to the particular index or None if not found\n","        \"\"\"\n","        if (index not in self.ints_to_objs):\n","            return None\n","        else:\n","            return self.ints_to_objs[index]\n","\n","    def contains(self, object):\n","        \"\"\"\n","        :param object: object to look up\n","        :return: Returns True if it is in the Indexer, False otherwise\n","        \"\"\"\n","        return self.index_of(object) != -1\n","\n","    def index_of(self, object):\n","        \"\"\"\n","        :param object: object to look up\n","        :return: Returns -1 if the object isn't present, index otherwise\n","        \"\"\"\n","        if (object not in self.objs_to_ints):\n","            return -1\n","        else:\n","            return self.objs_to_ints[object]\n","\n","    def add_and_get_index(self, object, add=True):\n","        \"\"\"\n","        Adds the object to the index if it isn't present, always returns a nonnegative index\n","        :param object: object to look up or add\n","        :param add: True by default, False if we shouldn't add the object. If False, equivalent to index_of.\n","        :return: The index of the object\n","        \"\"\"\n","        if not add:\n","            return self.index_of(object)\n","        if (object not in self.objs_to_ints):\n","            new_idx = len(self.objs_to_ints)\n","            self.objs_to_ints[object] = new_idx\n","            self.ints_to_objs[new_idx] = object\n","        return self.objs_to_ints[object]"],"metadata":{"id":"vVFCmhUbCyhE","executionInfo":{"status":"ok","timestamp":1650937658627,"user_tz":300,"elapsed":8,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class WordEmbeddings:\n","    \"\"\"\n","    Wraps an Indexer and a list of 1-D numpy arrays where each position in the list is the vector for the corresponding\n","    word in the indexer. The 0 vector is returned if an unknown word is queried.\n","    \"\"\"\n","    def __init__(self, word_indexer, vectors):\n","        self.word_indexer = word_indexer\n","        self.vectors = vectors\n","\n","    def get_embedding_length(self):\n","        return len(self.vectors[0])\n","\n","    def get_embedding(self, word):\n","        \"\"\"\n","        Returns the embedding for a given word\n","        :param word: The word to look up\n","        :return: The UNK vector if the word is not in the Indexer or the vector otherwise\n","        \"\"\"\n","        word_idx = self.word_indexer.index_of(word)\n","        if word_idx != -1:\n","            return self.vectors[word_idx]\n","        else:\n","            return self.vectors[self.word_indexer.index_of(\"UNK\")]"],"metadata":{"id":"RXD4qyHOPGUu","executionInfo":{"status":"ok","timestamp":1650937658628,"user_tz":300,"elapsed":9,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def read_word_embeddings(embeddings_file: str) -> WordEmbeddings:\n","    \"\"\"\n","    Loads the given embeddings (ASCII-formatted) into a WordEmbeddings object. Augments this with an UNK embedding\n","    that is the 0 vector. Reads in all embeddings with no filtering -- you should only use this for relativized\n","    word embedding files.\n","    :param embeddings_file: path to the file containing embeddings\n","    :return: WordEmbeddings object reflecting the words and their embeddings\n","    \"\"\"\n","    f = open(embeddings_file)\n","    word_indexer = Indexer()\n","    vectors = []\n","    # Make position 0 a PAD token, which can be useful if you\n","    word_indexer.add_and_get_index(\"PAD\")\n","    # Make position 1 the UNK token\n","    word_indexer.add_and_get_index(\"UNK\")\n","    for i, line in enumerate(f):\n","        if line.strip() != \"\":\n","            space_idx = line.find(' ')\n","            word = line[:space_idx]\n","            numbers = line[space_idx+1:]\n","            float_numbers = [float(number_str) for number_str in numbers.split()]\n","            vector = np.array(float_numbers)\n","            word_indexer.add_and_get_index(word)\n","            # Append the PAD and UNK vectors to start. Have to do this weirdly because we need to read the first line\n","            # of the file to see what the embedding dim is\n","            if len(vectors) == 0:\n","                vectors.append(np.zeros(vector.shape[0]))\n","                vectors.append(np.zeros(vector.shape[0]))\n","            vectors.append(vector)\n","        if i % 10000 == 0:\n","          print(f'done reading {i} embeddings')\n","    f.close()\n","    print(\"Read in \" + repr(len(word_indexer)) + \" vectors of size \" + repr(vectors[0].shape[0]))\n","    # Turn vectors into a 2-D numpy array\n","    return WordEmbeddings(word_indexer, np.array(vectors))"],"metadata":{"id":"eZuwuTwKFgtu","executionInfo":{"status":"ok","timestamp":1650937658628,"user_tz":300,"elapsed":8,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["embeddings = read_word_embeddings(\"/content/gdrive/MyDrive/embeddings/glove/baseline/glove.6B.50d.txt\")\n","print(len(embeddings.word_indexer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZhPMzXEFkRb","executionInfo":{"status":"ok","timestamp":1650937668421,"user_tz":300,"elapsed":9800,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"9c7375fd-b6ba-4c32-85af-293acb1d8dd3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["done reading 0 embeddings\n","done reading 10000 embeddings\n","done reading 20000 embeddings\n","done reading 30000 embeddings\n","done reading 40000 embeddings\n","done reading 50000 embeddings\n","done reading 60000 embeddings\n","done reading 70000 embeddings\n","done reading 80000 embeddings\n","done reading 90000 embeddings\n","done reading 100000 embeddings\n","done reading 110000 embeddings\n","done reading 120000 embeddings\n","done reading 130000 embeddings\n","done reading 140000 embeddings\n","done reading 150000 embeddings\n","done reading 160000 embeddings\n","done reading 170000 embeddings\n","done reading 180000 embeddings\n","done reading 190000 embeddings\n","done reading 200000 embeddings\n","done reading 210000 embeddings\n","done reading 220000 embeddings\n","done reading 230000 embeddings\n","done reading 240000 embeddings\n","done reading 250000 embeddings\n","done reading 260000 embeddings\n","done reading 270000 embeddings\n","done reading 280000 embeddings\n","done reading 290000 embeddings\n","done reading 300000 embeddings\n","done reading 310000 embeddings\n","done reading 320000 embeddings\n","done reading 330000 embeddings\n","done reading 340000 embeddings\n","done reading 350000 embeddings\n","done reading 360000 embeddings\n","done reading 370000 embeddings\n","done reading 380000 embeddings\n","done reading 390000 embeddings\n","Read in 400002 vectors of size 50\n","400002\n"]}]},{"cell_type":"code","source":["print(embeddings.word_indexer.index_of('particles'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3CCley7PUEK","executionInfo":{"status":"ok","timestamp":1650937668422,"user_tz":300,"elapsed":6,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"65d4c981-12a0-4248-85f8-9326e37b382a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["9100\n"]}]},{"cell_type":"code","source":["class RNN(nn.Module):\n","  def __init__(self, \n","               embedding_vectors,\n","               hidden_dim,\n","               output_dim):\n","    super().__init__()\n","\n","    self.embedding_vectors = embedding_vectors\n","    self.hidden_dim = hidden_dim\n","    self.output_dim = output_dim\n","\n","    weights = torch.FloatTensor(self.embedding_vectors)\n","    self.e1 = nn.Embedding.from_pretrained(weights, padding_idx=0)\n","    self.e1.requires_grad_(False)\n","\n","    self.lstm = nn.GRU(input_size=len(self.embedding_vectors[0]),\n","                       hidden_size=self.hidden_dim,\n","                       num_layers=1,\n","                       batch_first=True,\n","                       bidirectional=True)\n","    \n","    self.drop = nn.Dropout(p=0.3)\n","    self.fc = nn.Linear(2*self.hidden_dim, output_dim)\n","\n","  def forward(self, x):\n","\n","    sentence_mask = (x != 0).type(\n","            torch.cuda.LongTensor if x.is_cuda else\n","            torch.LongTensor)\n","    \n","    sentence_lengths = sentence_mask.sum(dim=1).cpu()\n","            \n","    x = self.e1(x)\n","\n","    packed_input = pack_padded_sequence(x, sentence_lengths, batch_first=True, enforce_sorted=False)\n","    packed_output, _ = self.lstm(packed_input)\n","    output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","    out_forward = output[range(len(output)), sentence_lengths - 1, :self.hidden_dim]\n","    out_reverse = output[:, 0, self.hidden_dim:]\n","    out_reduced = torch.cat((out_forward, out_reverse), 1)\n","    text_fea = self.drop(out_reduced)\n","\n","    x = self.fc(text_fea)\n","\n","    return x"],"metadata":{"id":"uFNvilwdPXIO","executionInfo":{"status":"ok","timestamp":1650937668422,"user_tz":300,"elapsed":3,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class RNNClassifier():\n","    \"\"\"\n","    Implement your NeuralSentimentClassifier here. This should wrap an instance of the network with learned weights\n","    along with everything needed to run it on new data (word embeddings, etc.)\n","    \"\"\"\n","    def __init__(self,\n","                 word_embeddings,\n","                 batch_size=128,\n","                 hidden_size=128,\n","                 output_size=5,\n","                 lr=0.001,\n","                 num_epochs=10,\n","                 seed=3):\n","\n","        # indexer between words and indexes => self.word_embeddings.word_indexer (indexer in utils)\n","        # 2D array of weights => self.word_embeddings.vectors (in sentiment_data)\n","        \n","        self.word_embeddings = word_embeddings\n","        self.batch_size = batch_size\n","        self.num_epochs = num_epochs\n","        self.lr = lr\n","        self.output_size = output_size\n","\n","        # random.seed(seed)\n","        # torch.manual_seed(seed)\n","\n","        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","        self.network = RNN(embedding_vectors=self.word_embeddings.vectors,\n","                           hidden_dim=hidden_size,\n","                           output_dim=output_size).to(device)\n","\n","        self.print_network()\n","\n","        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    def convert_to_idx_tensor(self, sentences):\n","        idx_encodings = []\n","        for sentence in sentences:\n","            idx_encoding = [0] * len(sentence)\n","            for idx, word in enumerate(sentence):\n","                word_idx = self.word_embeddings.word_indexer.index_of(word)\n","                idx_encoding[idx] = word_idx if word_idx != -1 else 1\n","            idx_encodings.append(idx_encoding)\n","        idx_encodings = torch.tensor(idx_encodings)\n","        return idx_encodings\n","\n","    def pad_sentences(self, batch):\n","        max_len = 0\n","        for sentiment_ex in batch:\n","            sentence = sentiment_ex.words\n","            max_len = max(max_len, len(sentence))\n","\n","        for sentiment_ex in batch:\n","            sentence = sentiment_ex.words\n","            sentence += ['PAD'] * (max_len - len(sentence))\n","\n","        return batch\n","\n","    def train(self, train_exs, dev_exs):\n","        \n","        loss_function = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(self.network.parameters(), lr=self.lr, weight_decay=0.0001)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.95)\n","\n","        max_dev_acc = 0\n","        best_weights = None\n","\n","        for epoch in range(self.num_epochs):\n","\n","            self.network.train()\n","            random.shuffle(train_exs)\n","\n","            \"\"\"\n","            Minibatch stuff\n","            \"\"\"\n","            idx = 0\n","            minibatch_train_exs = []\n","            for i in range(0, len(train_exs), self.batch_size):\n","                minibatch_train_exs.append(train_exs[i:i+self.batch_size])\n","                self.pad_sentences(minibatch_train_exs[idx])\n","                idx += 1\n","\n","            total_loss = 0\n","            for i, exs in enumerate(minibatch_train_exs):\n","\n","                if i % 100 == 0:\n","                  print(f'batch {i} complete')\n","\n","                train_x = [ex.words for ex in exs]\n","                train_y = [ex.label for ex in exs]\n","\n","                # convert word sentences to list of indexes and train_y to tensor\n","                x = self.convert_to_idx_tensor(train_x)\n","                y = torch.tensor(train_y)\n","\n","                x = x.to(self.device)\n","                y = y.to(self.device)\n","\n","                output = self.network(x)\n","\n","                loss = loss_function(output, y)\n","                total_loss += loss\n","    \n","                # update model weights\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","            # calculate validation set accuracy\n","            golds = [dev_ex.label for dev_ex in dev_exs]            \n","            predictions = self.predict_all([dev_ex.words for dev_ex in dev_exs])\n","            num_correct = 0\n","            for i in range(0, len(golds)):\n","                if golds[i] == predictions[i]:\n","                    num_correct += 1\n","\n","            dev_acc = num_correct/len(golds)\n","\n","            if dev_acc > max_dev_acc or epoch == 0:\n","                max_dev_acc = dev_acc\n","                best_weights = deepcopy(self.network.state_dict())\n","                print('saving model weights...')\n","\n","            scheduler.step()\n","\n","            print(f'Epoch Number = {epoch}, total loss = ', total_loss)\n","            print(f'Development Accuracy = {num_correct}/{len(golds)} = {dev_acc}')\n","\n","        self.network.load_state_dict(best_weights)\n","\n","    def predict(self, ex_words) -> int:\n","        idx_tensor = self.convert_to_idx_tensor([ex_words])\n","        idx_tensor = idx_tensor.to(self.device)\n","        output = self.network(idx_tensor)\n","        result = output.argmax(dim=1)\n","        return result[0]\n","\n","    def predict_all(self, all_ex_words):\n","        \"\"\"\n","        You can leave this method with its default implementation, or you can override it to a batched version of\n","        prediction if you'd like. Since testing only happens once, this is less critical to optimize than training\n","        for the purposes of this assignment.\n","        :param all_ex_words: A list of all exs to do prediction on\n","        :return:\n","        \"\"\"\n","        return [self.predict(ex_words) for ex_words in all_ex_words]\n","\n","    def print_network(self):\n","        print(self.network)"],"metadata":{"id":"zPJchdZ9Pj4V","executionInfo":{"status":"ok","timestamp":1650937668728,"user_tz":300,"elapsed":165,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def train_deep_averaging_network(train_exs, \n","                                 dev_exs,\n","                                 word_embeddings: WordEmbeddings) -> RNNClassifier:\n","    \"\"\"\n","    :param args: Command-line args so you can access them here\n","    :param train_exs: training examples\n","    :param dev_exs: development set, in case you wish to evaluate your model during training\n","    :param word_embeddings: set of loaded word embeddings\n","    :return: A trained NeuralSentimentClassifier model\n","    \"\"\"\n","\n","    # extract input information from args\n","    batch_size = 128 # args.batch_size\n","    hidden_size = 128 # args.hidden_size\n","    lr = 0.001 # args.lr\n","    num_epochs = 10 # args.num_epochs\n","    output_size = len(CLASS_LABELS.items())\n","\n","    classifier = RNNClassifier(word_embeddings=word_embeddings,\n","                               batch_size=batch_size, \n","                               hidden_size=hidden_size, \n","                               output_size=output_size,\n","                               lr=lr, \n","                               num_epochs=num_epochs)\n","\n","    start_time = time.time()\n","    classifier.train(train_exs=train_exs, dev_exs=dev_exs)\n","    end_time = time.time()\n","    total_time = int(end_time - start_time)\n","\n","    print(f'Total time taken => {total_time}s')\n","\n","    return classifier"],"metadata":{"id":"zpC4ekZmRWRQ","executionInfo":{"status":"ok","timestamp":1650937668728,"user_tz":300,"elapsed":3,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["model = train_deep_averaging_network(train_exs, validation_exs, embeddings)"],"metadata":{"id":"SNy4wvwrReUn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650938755824,"user_tz":300,"elapsed":1087098,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}},"outputId":"8c1c84e9-1fad-4d4f-d1e4-7c1c527a7b8b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["RNN(\n","  (e1): Embedding(400002, 50, padding_idx=0)\n","  (lstm): GRU(50, 128, batch_first=True, bidirectional=True)\n","  (drop): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=5, bias=True)\n",")\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 0, total loss =  tensor(1821.9852, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 52407/75015 = 0.698620275944811\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 1, total loss =  tensor(1727.5450, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 52864/75015 = 0.7047123908551624\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 2, total loss =  tensor(1693.5607, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53293/75015 = 0.7104312470839166\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 3, total loss =  tensor(1671.9678, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53318/75015 = 0.7107645137639139\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 4, total loss =  tensor(1658.2931, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53628/75015 = 0.7148970205958808\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","Epoch Number = 5, total loss =  tensor(1647.4000, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53473/75015 = 0.7128307671798974\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 6, total loss =  tensor(1637.5918, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53635/75015 = 0.7149903352662801\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 7, total loss =  tensor(1628.5717, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53730/75015 = 0.7162567486502699\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","saving model weights...\n","Epoch Number = 8, total loss =  tensor(1621.1420, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53834/75015 = 0.7176431380390589\n","batch 0 complete\n","batch 100 complete\n","batch 200 complete\n","batch 300 complete\n","batch 400 complete\n","batch 500 complete\n","batch 600 complete\n","batch 700 complete\n","batch 800 complete\n","batch 900 complete\n","batch 1000 complete\n","batch 1100 complete\n","batch 1200 complete\n","batch 1300 complete\n","batch 1400 complete\n","batch 1500 complete\n","batch 1600 complete\n","batch 1700 complete\n","batch 1800 complete\n","batch 1900 complete\n","batch 2000 complete\n","batch 2100 complete\n","batch 2200 complete\n","batch 2300 complete\n","Epoch Number = 9, total loss =  tensor(1612.1758, device='cuda:0', grad_fn=<AddBackward0>)\n","Development Accuracy = 53796/75015 = 0.7171365726854629\n","Total time taken => 1075s\n"]}]},{"cell_type":"code","source":["def get_confusion_matrix(model, exs):\n","  golds = [ex.label for ex in exs]\n","  predictions = model.predict_all([ex.words for ex in exs])\n","\n","  confusion_matrix = [[0] * len(CLASS_LABELS.items()) for i in range(len(CLASS_LABELS.items()))]  \n","  num_correct = 0\n","  for i in range(0, len(golds)):\n","    if golds[i] == predictions[i]:\n","      num_correct += 1\n","    confusion_matrix[golds[i]][predictions[i]] += 1\n","\n","  return num_correct, confusion_matrix"],"metadata":{"id":"-Qs08kaKGIvL","executionInfo":{"status":"ok","timestamp":1650938755825,"user_tz":300,"elapsed":6,"user":{"displayName":"NLP Final","userId":"00834871271301784662"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["num_correct, confusion_matrix = get_confusion_matrix(model, validation_exs)"],"metadata":{"id":"L6ip0UJWHNBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pprint.pprint(confusion_matrix)"],"metadata":{"id":"w5vR17rmHPNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","data = np.random.rand(8, 8)\n","ax = sns.heatmap(confusion_matrix, linewidth=0.3)\n","ax.set(xlabel='Predicted', ylabel='Gold')\n","plt.show()"],"metadata":{"id":"AngSk1JIHSLb"},"execution_count":null,"outputs":[]}]}